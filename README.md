# Internal-Control-Enhancement
Audit Risk Assessment for Internal Control Enhancement using Flask and RandomForestClassifier


This project presents a web-based system designed to assess and predict audit risk, directly contributing to the proactive enhancement of an organization's internal controls. By leveraging a machine learning model (**RandomForestClassifier**) and an intuitive Flask web application, it aims to identify potential "High Risk" areas within audit data, enabling targeted and data-driven improvements to control mechanisms.

## Features

* **Proactive Risk Identification:** Predicts if a given set of audit parameters indicates "High Risk" or "Low Risk". This capability allows organizations to anticipate and address control weaknesses before they lead to significant issues.
* **Data-Driven Control Enhancement:** The system utilizes historical audit data to inform where internal controls are most vulnerable, guiding the strategic allocation of resources for control improvements.
* **Performance Monitoring & Audit Trail:** All user inputs and corresponding predictions are logged to an Excel file (`predictions_log.xlsx`). This creates a traceable record of risk assessments, which is crucial for monitoring the effectiveness of implemented control enhancements over time.
* **Analytical Insights for Control Gaps:** Performs a basic Exploratory Data Analysis (EDA) on the `audit_data.csv` dataset, generating a summary report (`basic_eda_report.txt`). These insights into data patterns, missing values, and descriptive statistics can help in identifying potential control gaps or data quality issues that impact overall control effectiveness.
* **User-Friendly Interface:** Provides a straightforward web interface for inputting audit data and viewing immediate risk predictions, facilitating quick action by control owners or audit teams.
* **Downloadable Log for Further Analysis:** Allows for easy download of the `predictions_log.xlsx`, enabling deeper offline analysis of risk trends and control performance.

## Requirements

Ensure you have the following Python libraries installed:

* **Python 3.x**
* **Flask:** Web framework for building the application.
* **Pandas:** For data manipulation, reading CSV/Excel files, and EDA.
* **scikit-learn:** For machine learning, specifically `RandomForestClassifier`.
* **joblib:** For saving and loading the trained machine learning model.
* **openpyxl:** Required by Pandas for handling `.xlsx` files.

You can install these dependencies using `pip` from a `requirements.txt` file (which you would create).

## Installation and Setup

### Project Structure:

/your-project-directory
│── audit_data.csv                      # Your dataset (must be in the root)
│── risk_model.pkl                      # Trained machine learning model (generated by model.py)
│── /outputs                            # Directory for EDA report and prediction log
│   ├── basic_eda_report.txt
│   └── predictions_log.xlsx
│── /templates                          # HTML templates for the web interface
│   ├── landing.html
│   ├── input.html
│   └── result.html
│── app.py                              # Flask web application
│── model.py                            # Model training script
│── requirements.txt                    # Python dependencies (create this file)
│── README.md                           # Project documentation (this file)


### Steps:

1.  **Place your dataset:** Ensure your dataset, named `audit_data.csv`, is located in the root directory of your project (the same directory as `app.py` and `model.py`).

2.  **Create `requirements.txt`:** Create a file named `requirements.txt` in your project root with the following content:

    ```
    Flask
    pandas
    scikit-learn
    joblib
    openpyxl
    ```

3.  **Set up a virtual environment (optional but recommended):**

    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

4.  **Install dependencies:**

    ```bash
    pip install -r requirements.txt
    ```

5.  **Train the Machine Learning Model:** Run the `model.py` script **once** to train the `RandomForestClassifier` and save it as `risk_model.pkl`.

    ```bash
    python model.py
    ```

    This script will:
    * Load `audit_data.csv`.
    * Select features like 'Audit_Risk', 'Inherent_Risk', 'Score', 'TOTAL', 'Money_Value' and the 'Risk' target variable.
    * Split the data into training and test sets.
    * Train a `RandomForestClassifier`.
    * Save the trained model to `risk_model.pkl`.

6.  **Run the Flask Application:**

    ```bash
    python app.py
    ```
    This will start the Flask development server.

7.  **Access the Application:** Open your web browser and navigate to `http://127.0.0.1:5000`.

## Project Structure (Detailed)

* `audit_data.csv`: The primary dataset used for both model training and EDA. It should contain columns such as `Audit_Risk`, `Inherent_Risk`, `Score`, `TOTAL`, `Money_Value`, and `Risk`.
* `risk_model.pkl`: The serialized (trained) `RandomForestClassifier` model generated by `model.py`. This file is loaded by `app.py` to make predictions.
* `/outputs/`: This directory is created by the `app.py` script.
    * `basic_eda_report.txt`: A text file containing the summary of the EDA performed by `app.py` (data overview, types, null values, descriptive statistics).
    * `predictions_log.xlsx`: An Excel file where all submitted predictions and their corresponding input values are logged.
* `/templates/`: Contains the HTML templates for the web interface:
    * `landing.html`: The initial page users see when accessing the application.
    * `input.html`: The form where users input the audit parameters for prediction.
    * `result.html`: Displays the prediction outcome (High Risk or Low Risk) and the submitted input values.
* `app.py`: The main Flask application script. It handles:
    * Loading the pre-trained `risk_model.pkl`.
    * Defining routes for the landing page (`/`), input form (`/input`), prediction handling (`/predict`), and downloading the log file (`/download_predictions_log`).
    * Calling `run_basic_eda()` which loads `audit_data.csv`, performs basic EDA, and saves the `basic_eda_report.txt`.
    * Processing form submissions, making predictions, and saving inputs/predictions to `predictions_log.xlsx`.
* `model.py`: A separate script responsible for loading `audit_data.csv`, selecting features, splitting data, training the `RandomForestClassifier`, and saving the trained model to `risk_model.pkl`.
* `requirements.txt`: Lists all Python packages required for the project.

## Usage

1.  **Model Training:** Ensure you run `python model.py` first to train the risk prediction model and establish a baseline for identifying control weaknesses.
2.  **System Deployment:** Execute `python app.py` to start the Flask web application, providing an accessible tool for continuous risk assessment.
3.  **Proactive Assessment:** Access the application via your web browser (`http://127.0.0.1:5000`) and navigate to the input form. Input new audit parameters (e.g., Audit Risk, Inherent Risk, Score, TOTAL, Money Value) to identify "High Risk" areas. This helps in understanding where existing internal controls might be failing or are insufficient.
4.  **Control Review & Enhancement:** Use the "High Risk" predictions as a trigger to review and enhance specific internal controls that are identified as weak or vulnerable.
5.  **Performance Monitoring:** Utilize the downloaded `predictions_log.xlsx` to track changes in risk over time. This data is invaluable for monitoring the effectiveness of implemented control enhancements and demonstrating their impact.
6.  **Data-Driven Insights:** Refer to the `basic_eda_report.txt` (generated in the `outputs` directory) for deeper insights into data characteristics. This can reveal systemic issues or data quality problems that might impact the reliability of your internal controls.
